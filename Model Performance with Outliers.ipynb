{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "         .:::.     .::.       \n",
      "        ....yy:    .yy.       \n",
      "        :.  .yy.    y.        \n",
      "             :y:   .:         \n",
      "             .yy  .:          \n",
      "              yy..:           \n",
      "              :y:.            \n",
      "              .y.             \n",
      "             .:.              \n",
      "        ....:.                \n",
      "        :::.                  \n",
      "\u001b[0;33m\n",
      "• Project files and data should be stored in /project. This is shared among everyone\n",
      "  in the project.\n",
      "• Personal files and configuration should be stored in /home/faculty.\n",
      "• Files outside /project and /home/faculty will be lost when this server is terminated.\n",
      "• Create custom environments to setup your servers reproducibly.\n",
      "\u001b[0m\n",
      "Requirement already satisfied: plotly in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (5.2.2)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from plotly) (8.0.1)\n",
      "Requirement already satisfied: six in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from plotly) (1.15.0)\n",
      "\u001b[1m\n",
      "         .:::.     .::.       \n",
      "        ....yy:    .yy.       \n",
      "        :.  .yy.    y.        \n",
      "             :y:   .:         \n",
      "             .yy  .:          \n",
      "              yy..:           \n",
      "              :y:.            \n",
      "              .y.             \n",
      "             .:.              \n",
      "        ....:.                \n",
      "        :::.                  \n",
      "\u001b[0;33m\n",
      "• Project files and data should be stored in /project. This is shared among everyone\n",
      "  in the project.\n",
      "• Personal files and configuration should be stored in /home/faculty.\n",
      "• Files outside /project and /home/faculty will be lost when this server is terminated.\n",
      "• Create custom environments to setup your servers reproducibly.\n",
      "\u001b[0m\n",
      "Requirement already satisfied: xgboost in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (1.4.2)\n",
      "Requirement already satisfied: scipy in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from xgboost) (1.6.2)\n",
      "Requirement already satisfied: numpy in /home/faculty/.local/lib/python3.8/site-packages (from xgboost) (1.19.5)\n"
     ]
    }
   ],
   "source": [
    "#Install Necessary Packages\n",
    "!pip install --upgrade plotly\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Packages/Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Necessary Packages / libraries\n",
    "import os #provides functions for interacting with the operating system\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from numpy import asarray\n",
    "from pandas import to_datetime\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import datetime\n",
    "%matplotlib inline\n",
    "import plotly.express as px\n",
    "#importing packaging for OrdinalEncoding to transform categorical variable\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "#importing model_selection and timeseriessplit for cross time series forecasting\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "#error metrics for regression from sklearn package\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "#Import machine learning regressor model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# To change scientific numbers to float\n",
    "np.set_printoptions(formatter={'float_kind':'{:f}'.format})\n",
    "# Increases the size of sns plots\n",
    "sns.set(rc={'figure.figsize':(8,6)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laoding Main Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing main dataset\n",
    "sales_order=pd.read_excel(\"/project/MACHINE_LEARNING_DATA_SET_Stock.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Barking\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mode of warehouse_name variable in the main dataset\n",
    "sales_order.warehouse_name.mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing the missing value of warehouse_name\n",
    "sales_order['warehouse_name'].replace(np.nan, 'Barking',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_product_segmentation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c4dd83f68488>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Segmenting Products into two categories based on 75% threshold for ordered quantity and price.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_product_segmentation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'product_segmentation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_product_segmentation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'INVOICED'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m5.578835e+03\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m|\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_product_segmentation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'QUANTITY'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m113\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'high_demand_products'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'low_demand_products'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_product_segmentation' is not defined"
     ]
    }
   ],
   "source": [
    "#Segmenting Products into two categories based on 75% threshold for ordered quantity and price. \n",
    "df_product_segmentation['product_segmentation']=np.where((df_product_segmentation['INVOICED']>5.578835e+03)|(df_product_segmentation['QUANTITY']>113),'high_demand_products','low_demand_products')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping price and quantity columns before mergring with the main dataset to prevenet create duplicate variables. \n",
    "df_product_segmentation=df_product_segmentation.drop(columns=['INVOICED','QUANTITY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking how many products each category has.\n",
    "df_product_segmentation.groupby('product_segmentation').STOCK_CODE.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging product category column with the main dataset\n",
    "sales_order= pd.merge(sales_order, \n",
    "                      df_product_segmentation, \n",
    "                      on ='STOCK_CODE', \n",
    "                      how ='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#customer count for each day\n",
    "customer_count=sales_order.groupby(by=['INVOICE_DATE'], as_index=False)['NAME'].nunique()\n",
    "customer_count.rename(columns={'NAME':'Customer_count'}, inplace=True)\n",
    "sales_order=pd.merge(sales_order, customer_count, how='left',on='INVOICE_DATE')\n",
    "\n",
    "# Feature engineering day,month, year from date \n",
    "sales_order['week_number_of_year'] = sales_order['INVOICE_DATE'].dt.week\n",
    "sales_order['day_number_of_week'] = sales_order['INVOICE_DATE'].dt.day\n",
    "sales_order['month_number_of_year'] = sales_order['INVOICE_DATE'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting variables for Machine Learning Dataset by storing variables in df_model\n",
    "df_model=sales_order[['INVOICE_DATE','warehouse_name','STOCK_CODE','week_number_of_year',\n",
    "                      'day_number_of_week','month_number_of_year','STOCK','QUANTITY','INVOICED','Customer_count',\n",
    "                      'product_segmentation','AVERAGE_COST_PRICE', 'LAST_PURCHASE_PRICE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model=df_model.groupby(by=['INVOICE_DATE','warehouse_name','STOCK_CODE','week_number_of_year','day_number_of_week','month_number_of_year','Customer_count','product_segmentation'], as_index=False)[['AVERAGE_COST_PRICE', 'LAST_PURCHASE_PRICE','QUANTITY','INVOICED','STOCK']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rouding the figures in these variables \n",
    "df_model.INVOICED=df_model.INVOICED.round()\n",
    "df_model.QUANTITY=df_model.QUANTITY.round()\n",
    "df_model.STOCK=df_model.STOCK.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforming all observation to string as the product column contains mix of text and integers\n",
    "df_model['STOCK_CODE'] = df_model['STOCK_CODE'].astype(str)\n",
    "ohe=OrdinalEncoder()\n",
    "products=ohe.fit_transform(asarray(df_model['STOCK_CODE']).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_name=pd.DataFrame(products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.index=product_name.index\n",
    "df_model=pd.concat([df_model,product_name], axis=1)\n",
    "df_model.rename(columns={0:'product'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.loc[(df_model.product_segmentation=='high_demand_products'),'product_segment']=1 \n",
    "df_model.loc[(df_model.product_segmentation=='low_demand_products'),'product_segment']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_warehouse=pd.get_dummies(df_model['warehouse_name'], prefix='warehouse_', drop_first=False)\n",
    "df_model.index = df_warehouse.index\n",
    "df_model = pd.concat([df_model, df_warehouse], axis=1)\n",
    "df_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Correlation Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr=df_model.drop(columns=['warehouse_name','STOCK_CODE','product_segmentation', 'INVOICE_DATE'])\n",
    "\n",
    "corr_matrix= df_corr.corr()\n",
    "corr_matrix['QUANTITY'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,9))\n",
    "plt.yticks(fontsize=10)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.title('Correlation of Different Variables with Demand Outcome - QUANTITY', fontsize=15)\n",
    "sns.heatmap(df_corr.corr(method='pearson'),annot=True,cmap='seismic');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Spliting with Time Series Nested Cross - Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_cv=df_model.set_index('INVOICE_DATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_cv.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_cv=df_model_cv.drop(columns=['warehouse_name','STOCK_CODE','product_segmentation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_cv = df_model_cv[['week_number_of_year', 'day_number_of_week', 'month_number_of_year',\n",
    "        'INVOICED', 'STOCK', 'product','product_segment','Customer_count','AVERAGE_COST_PRICE', 'LAST_PURCHASE_PRICE','warehouse__Barking',\n",
    "       'warehouse__Great Yarmouth', 'warehouse__Thetford',\n",
    "       'warehouse__Waltham Abbey','QUANTITY']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference https://www.angioi.com/time-nested-cv-with-sklearn/?fbclid=IwAR0bnOugMIqE-Hhhb8cgy9Lk81d9Xp8jwYJZf7IEO3Pq3iJ5LKUe7k-J8D4\n",
    "n_splits = 3 #Number of train/cv/test folds\n",
    "\n",
    "trainTestSplit = TimeSeriesSplit(n_splits+1).split(df_model_cv)\n",
    "next(trainTestSplit)\n",
    "\n",
    "\n",
    "for trainCvIndices, testIndices in trainTestSplit:\n",
    "    # First, we split Train + CV and Test\n",
    "    X_traincv, y_traincv = df_model_cv.iloc[trainCvIndices,0:14], df_model_cv.iloc[trainCvIndices,-1]\n",
    "    X_test, y_test     = df_model_cv.iloc[testIndices,0:14]   , df_model_cv.iloc[testIndices,-1]\n",
    "    \n",
    "    # Then, we build a list of the form [ ( [...Train Indices...], [...CV Indices...]  )]\n",
    "    testLength = len(X_test)\n",
    "    trainCvSplit = [(list(range(trainCvIndices[0],trainCvIndices[-testLength])),\n",
    "                     list(range(trainCvIndices[-testLength],trainCvIndices[-1]+1)))]\n",
    "    \n",
    "    # Printing date ranges\n",
    "    print(\"Training:\"           , X_traincv.index[0].date(), \"--\", X_traincv.index[-testLength-1].date(),\n",
    "          \", Cv:\"     , X_traincv.index[-testLength].date(), \"--\", X_traincv.index[-1].date(),\n",
    "          \", Test:\"                , X_test.index[0].date(), \"--\", X_test.index[-1].date())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Result on Default Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Model Regression (Baseline Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "#Fit the model\n",
    "model.fit(X_traincv, y_traincv)\n",
    "#Get predictions for the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred,squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mape=mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "# Check the score on train and test\n",
    "print('RMSE: {}'.format(rmse))\n",
    "print('MAE: {}'.format(mae))\n",
    "print('r^2 score on train set: {}'.format(model.score(X_traincv, y_traincv)))\n",
    "print('r^2 score on test set: {}'.format(model.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a KNN regression model with default arguments\n",
    "model = KNeighborsRegressor()\n",
    "#Fit the model\n",
    "model.fit(X_traincv, y_traincv)\n",
    "#Get predictions for the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred,squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mape=mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "# Check the score on train and test\n",
    "print('RMSE: {}'.format(rmse))\n",
    "print('MAE: {}'.format(mae))\n",
    "print('r^2 score on train set: {}'.format(model.score(X_traincv, y_traincv)))\n",
    "print('r^2 score on test set: {}'.format(model.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(random_state=42)\n",
    "#Fit the model\n",
    "model.fit(X_traincv, y_traincv)\n",
    "#Get predictions for the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred,squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mape=mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "# Check the score on train and test\n",
    "print('RMSE: {}'.format(rmse))\n",
    "print('MAE: {}'.format(mae))\n",
    "print('r^2 score on train set: {}'.format(model.score(X_traincv, y_traincv)))\n",
    "print('r^2 score on test set: {}'.format(model.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "#Fit the model\n",
    "model.fit(X_traincv, y_traincv)\n",
    "#Get predictions for the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred,squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mape=mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "# Check the score on train and test\n",
    "print('RMSE: {}'.format(rmse))\n",
    "print('MAE: {}'.format(mae))\n",
    "print('r^2 score on train set: {}'.format(model.score(X_traincv, y_traincv)))\n",
    "print('r^2 score on test set: {}'.format(model.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBOOST\n",
    "\n",
    "# Create a XGB regression model with default arguments\n",
    "model = XGBRegressor(random_state=42)\n",
    "#Fit the model\n",
    "model.fit(X_traincv, y_traincv)\n",
    "#Get predictions for the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred,squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mape=mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "# Check the score on train and test\n",
    "print('RMSE: {}'.format(rmse))\n",
    "print('MAE: {}'.format(mae))\n",
    "print('r^2 score on train set: {}'.format(model.score(X_traincv, y_traincv)))\n",
    "print('r^2 score on test set: {}'.format(model.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Results with Tuned Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression(positive=False, normalize=False, n_jobs=-1,fit_intercept=True)\n",
    "\n",
    "#Fit the model\n",
    "model.fit(X_traincv, y_traincv)\n",
    "#Get predictions for the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred,squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mape=mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "# Check the score on train and test\n",
    "print('RMSE: {}'.format(rmse))\n",
    "print('MAE: {}'.format(mae))\n",
    "print('r^2 score on train set: {}'.format(model.score(X_traincv, y_traincv)))\n",
    "print('r^2 score on test set: {}'.format(model.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsRegressor(n_neighbors= 11, p=2, weights='distance',metric='euclidean',leaf_size=30,algorithm='brute')\n",
    "\n",
    "#Fit the model\n",
    "model.fit(X_traincv, y_traincv)\n",
    "#Get predictions for the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred,squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mape=mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "# Check the score on train and test\n",
    "print('RMSE: {}'.format(rmse))\n",
    "print('MAE: {}'.format(mae))\n",
    "print('r^2 score on train set: {}'.format(model.score(X_traincv, y_traincv)))\n",
    "print('r^2 score on test set: {}'.format(model.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators=950,\n",
    " min_samples_split= 10,\n",
    " min_samples_leaf= 2,\n",
    " max_features='log2',\n",
    " max_depth=16,\n",
    " bootstrap=False, random_state=42)\n",
    "#Fit the model\n",
    "model.fit(X_traincv, y_traincv)\n",
    "#Get predictions for the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred,squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mape=mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "# Check the score on train and test\n",
    "print('RMSE: {}'.format(rmse))\n",
    "print('MAE: {}'.format(mae))\n",
    "print('r^2 score on train set: {}'.format(model.score(X_traincv, y_traincv)))\n",
    "print('r^2 score on test set: {}'.format(model.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingRegressor(n_estimators=300,\n",
    "          max_depth=6,\n",
    "          min_samples_split=2,\n",
    "          min_samples_leaf= 1,\n",
    "          max_features='auto',\n",
    "        subsample=1,\n",
    "random_state=42)\n",
    "\n",
    "#Fit the model\n",
    "model.fit(X_traincv, y_traincv)\n",
    "#Get predictions for the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred,squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mape=mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "# Check the score on train and test\n",
    "print('RMSE: {}'.format(rmse))\n",
    "print('MAE: {}'.format(mae))\n",
    "print('r^2 score on train set: {}'.format(model.score(X_traincv, y_traincv)))\n",
    "print('r^2 score on test set: {}'.format(model.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor(n_estimators=100,\n",
    "                     subsample=1,\n",
    "objective= 'reg:squarederror',\n",
    "reg_alpha=9,\n",
    "reg_lambda=10,\n",
    "min_child_weight= 35,\n",
    "max_depth= 20,\n",
    "gamma= 20,\n",
    "eta=0.2,\n",
    "colsample_bytree=0.5,\n",
    "random_state=42)\n",
    "\n",
    "#Fit the model\n",
    "model.fit(X_traincv, y_traincv)\n",
    "#Get predictions for the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred,squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Check the score on train and test\n",
    "print('RMSE: {}'.format(rmse))\n",
    "print('MAE: {}'.format(mae))\n",
    "print('r^2 score on train set: {}'.format(model.score(X_traincv, y_traincv)))\n",
    "print('r^2 score on test set: {}'.format(model.score(X_test,y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Python3] *",
   "language": "python",
   "name": "conda-env-Python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
